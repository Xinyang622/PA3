{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(22),\n",
    "     transforms.Scale(32),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./datasets/CIFAR-10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./datasets/CIFAR-10', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset) / 100,\n",
    "#                                          shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./datasets/CIFAR-10', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader1 = torch.utils.data.DataLoader(testset, batch_size=len(testset),\n",
    "                                          shuffle=False, num_workers=1)\n",
    "testloader2 = torch.utils.data.DataLoader(testset, batch_size=len(testset)/100,\n",
    "                                          shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.RandomHorizontalFlip(),\n",
    "#      transforms.RandomCrop(22),\n",
    "#      transforms.Scale(32),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./datasets/CIFAR-10', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./datasets/CIFAR-10', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset) / 100,\n",
    "#                                          shuffle=False, num_workers=1)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
    "def train_valid_loader(data, batchSize, nWorker, validSize=0.1, shuffle=True, pin_memory=True):\n",
    "    nTrain = len(data)\n",
    "    indices = list(range(nTrain))\n",
    "    split = int(np.floor(validSize * nTrain))\n",
    "    if shuffle == True:\n",
    "        #np.random.seed(randSeed)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    train_i, valid_i = indices[split:], indices[:split]\n",
    "    \n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_i)\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_i)\n",
    "    \n",
    "    trainLoader = torch.utils.data.DataLoader(data, \n",
    "                    batch_size=batchSize, sampler=train_sampler, \n",
    "                    num_workers=nWorker, pin_memory=pin_memory)\n",
    "    \n",
    "    validLoader = torch.utils.data.DataLoader(data, \n",
    "                    batch_size=batchSize, sampler=valid_sampler, \n",
    "                    num_workers=nWorker, pin_memory=pin_memory)\n",
    "    return  trainLoader, validLoader, train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 40)\n"
     ]
    }
   ],
   "source": [
    "trainloader, validloader, nSample = train_valid_loader(trainset, 128, 1, \n",
    "                                           validSize=0.1, shuffle=True, pin_memory=True)\n",
    "print (len(trainloader), len(validloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(3, 46, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv1_bn): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(46, 92, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2_bn): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv3): Conv2d(92, 184, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (conv3_bn): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv4): Conv2d(184, 368, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4_bn): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv5): Conv2d(368, 736, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5_bn): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc1): Linear (47104 -> 1024)\n",
      "  (fc2): Linear (1024 -> 256)\n",
      "  (fc3): Linear (256 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 46, 5, padding = 2)\n",
    "        #torch.nn.init.xavier_normal(self.conv1.weight)\n",
    "        self.conv1_bn = nn.BatchNorm2d(46)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(46, 92, 5, padding = 2)\n",
    "        #torch.nn.init.xavier_normal(self.conv2.weight)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.conv2_bn = nn.BatchNorm2d(92)\n",
    "        \n",
    "        self.conv3  = nn.Conv2d(92, 184, 5, padding = 2, stride = 2)\n",
    "        #torch.nn.init.xavier_normal(self.conv3.weight)\n",
    "        self.conv3_bn = nn.BatchNorm2d(184)\n",
    "        \n",
    "        self.conv4  = nn.Conv2d(184, 368 , 5, padding = 2)\n",
    "        #torch.nn.init.xavier_normal(self.conv4.weight)\n",
    "        self.conv4_bn = nn.BatchNorm2d(368)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(368, 736, 5, padding = 2)\n",
    "        self.conv5_bn = nn.BatchNorm2d(736)\n",
    "        \n",
    "#         self.conv6 = nn.Conv2d(512, 768, 5, padding = 2)\n",
    "#         self.conv6_bn = nn.BatchNorm2d(768)\n",
    "        \n",
    "        self.fc1 = nn.Linear(736 * 8 * 8, 1024)\n",
    "        #torch.nn.init.xavier_normal(self.fc1.weight)\n",
    "        #self.fc1_bn = nn.BatchNorm1d(1472)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        #torch.nn.init.xavier_normal(self.fc2.weight)\n",
    "        #self.fc2_bn = nn.BatchNorm1d(120)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        #torch.nn.init.xavier_normal(self.fc3.weight)\n",
    "        #self.fc3_bn = nn.BatchNorm1d(84)\n",
    "        \n",
    "#         self.fc4 = nn.Linear(84, 10)\n",
    "#         torch.nn.init.xavier_normal(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.rrelu(self.conv1_bn(self.conv1(x)))   \n",
    "        x = F.rrelu(self.conv2_bn(self.conv2(x))) \n",
    "        x = F.rrelu(self.conv3_bn(self.conv3(x)))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.rrelu(self.conv4_bn(self.conv4(x)))\n",
    "        # x = F.rrelu(self.conv5_bn(self.conv5(x)))\n",
    "        x = F.max_pool2d(F.rrelu(self.conv5_bn(self.conv5(x))), 2)\n",
    "        \n",
    "        #x = F.max_pool2d(F.rrelu(self.conv4_bn(self.conv4(x))), 2)\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "#         x = F.rrelu(self.fc1_bn(self.fc1(x)))\n",
    "#         x = F.rrelu(self.fc2_bn(self.fc2(x)))\n",
    "#         x = F.rrelu(self.fc3_bn(self.fc3(x)))\n",
    "        x = F.rrelu(self.fc1(x))\n",
    "        x = F.rrelu(self.fc2(x))\n",
    "        #x = F.rrelu(self.fc3(x))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net = net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.003, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        outputs = net(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "    return 1.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   352] loss: 4.087\n",
      "Accuracy of the network on the 45000 train images: 30.49 %\n",
      "Accuracy of the network on the 5000 valid images: 32.16 %\n",
      "Accuracy of the network on the 10000 test images: 33.53 %\n",
      "[2,   352] loss: 2.136\n",
      "Accuracy of the network on the 45000 train images: 36.63 %\n",
      "Accuracy of the network on the 5000 valid images: 36.56 %\n",
      "Accuracy of the network on the 10000 test images: 40.63 %\n",
      "[3,   352] loss: 1.949\n",
      "Accuracy of the network on the 45000 train images: 41.68 %\n",
      "Accuracy of the network on the 5000 valid images: 42.36 %\n",
      "Accuracy of the network on the 10000 test images: 44.38 %\n",
      "[4,   352] loss: 1.809\n",
      "Accuracy of the network on the 45000 train images: 46.99 %\n",
      "Accuracy of the network on the 5000 valid images: 47.68 %\n",
      "Accuracy of the network on the 10000 test images: 49.37 %\n",
      "[5,   352] loss: 1.660\n",
      "Accuracy of the network on the 45000 train images: 49.18 %\n",
      "Accuracy of the network on the 5000 valid images: 49.62 %\n",
      "Accuracy of the network on the 10000 test images: 50.71 %\n",
      "[6,   352] loss: 1.540\n",
      "Accuracy of the network on the 45000 train images: 57.10 %\n",
      "Accuracy of the network on the 5000 valid images: 56.28 %\n",
      "Accuracy of the network on the 10000 test images: 58.31 %\n",
      "[7,   352] loss: 1.439\n",
      "Accuracy of the network on the 45000 train images: 55.41 %\n",
      "Accuracy of the network on the 5000 valid images: 53.72 %\n",
      "Accuracy of the network on the 10000 test images: 53.17 %\n",
      "[8,   352] loss: 1.365\n",
      "Accuracy of the network on the 45000 train images: 61.30 %\n",
      "Accuracy of the network on the 5000 valid images: 61.14 %\n",
      "Accuracy of the network on the 10000 test images: 60.41 %\n",
      "[9,   352] loss: 1.288\n",
      "Accuracy of the network on the 45000 train images: 62.06 %\n",
      "Accuracy of the network on the 5000 valid images: 61.22 %\n",
      "Accuracy of the network on the 10000 test images: 62.92 %\n",
      "[10,   352] loss: 1.226\n",
      "Accuracy of the network on the 45000 train images: 65.29 %\n",
      "Accuracy of the network on the 5000 valid images: 64.54 %\n",
      "Accuracy of the network on the 10000 test images: 65.03 %\n",
      "[11,   352] loss: 1.162\n",
      "Accuracy of the network on the 45000 train images: 64.99 %\n",
      "Accuracy of the network on the 5000 valid images: 64.12 %\n",
      "Accuracy of the network on the 10000 test images: 67.63 %\n",
      "[12,   352] loss: 1.124\n",
      "Accuracy of the network on the 45000 train images: 67.92 %\n",
      "Accuracy of the network on the 5000 valid images: 66.88 %\n",
      "Accuracy of the network on the 10000 test images: 68.60 %\n",
      "[13,   352] loss: 1.079\n",
      "Accuracy of the network on the 45000 train images: 69.01 %\n",
      "Accuracy of the network on the 5000 valid images: 67.70 %\n",
      "Accuracy of the network on the 10000 test images: 68.01 %\n",
      "[14,   352] loss: 1.050\n",
      "Accuracy of the network on the 45000 train images: 70.47 %\n",
      "Accuracy of the network on the 5000 valid images: 69.40 %\n",
      "Accuracy of the network on the 10000 test images: 69.73 %\n",
      "[15,   352] loss: 1.027\n",
      "Accuracy of the network on the 45000 train images: 70.70 %\n",
      "Accuracy of the network on the 5000 valid images: 69.02 %\n",
      "Accuracy of the network on the 10000 test images: 70.28 %\n",
      "[16,   352] loss: 0.996\n",
      "Accuracy of the network on the 45000 train images: 70.57 %\n",
      "Accuracy of the network on the 5000 valid images: 69.58 %\n",
      "Accuracy of the network on the 10000 test images: 71.37 %\n",
      "[17,   352] loss: 0.966\n",
      "Accuracy of the network on the 45000 train images: 72.47 %\n",
      "Accuracy of the network on the 5000 valid images: 71.20 %\n",
      "Accuracy of the network on the 10000 test images: 72.45 %\n",
      "[18,   352] loss: 0.944\n",
      "Accuracy of the network on the 45000 train images: 73.12 %\n",
      "Accuracy of the network on the 5000 valid images: 71.70 %\n",
      "Accuracy of the network on the 10000 test images: 72.32 %\n",
      "[19,   352] loss: 0.934\n",
      "Accuracy of the network on the 45000 train images: 73.66 %\n",
      "Accuracy of the network on the 5000 valid images: 72.38 %\n",
      "Accuracy of the network on the 10000 test images: 71.76 %\n",
      "[20,   352] loss: 0.911\n",
      "Accuracy of the network on the 45000 train images: 73.94 %\n",
      "Accuracy of the network on the 5000 valid images: 72.66 %\n",
      "Accuracy of the network on the 10000 test images: 74.14 %\n",
      "[21,   352] loss: 0.899\n",
      "Accuracy of the network on the 45000 train images: 74.52 %\n",
      "Accuracy of the network on the 5000 valid images: 72.86 %\n",
      "Accuracy of the network on the 10000 test images: 72.73 %\n",
      "[22,   352] loss: 0.881\n",
      "Accuracy of the network on the 45000 train images: 75.60 %\n",
      "Accuracy of the network on the 5000 valid images: 73.32 %\n",
      "Accuracy of the network on the 10000 test images: 73.68 %\n",
      "[23,   352] loss: 0.863\n",
      "Accuracy of the network on the 45000 train images: 75.35 %\n",
      "Accuracy of the network on the 5000 valid images: 74.24 %\n",
      "Accuracy of the network on the 10000 test images: 73.06 %\n",
      "[24,   352] loss: 0.853\n",
      "Accuracy of the network on the 45000 train images: 74.88 %\n",
      "Accuracy of the network on the 5000 valid images: 72.18 %\n",
      "Accuracy of the network on the 10000 test images: 74.42 %\n",
      "[25,   352] loss: 0.853\n",
      "Accuracy of the network on the 45000 train images: 75.35 %\n",
      "Accuracy of the network on the 5000 valid images: 73.94 %\n",
      "Accuracy of the network on the 10000 test images: 73.97 %\n",
      "[26,   352] loss: 0.836\n",
      "Accuracy of the network on the 45000 train images: 75.08 %\n",
      "Accuracy of the network on the 5000 valid images: 73.54 %\n",
      "Accuracy of the network on the 10000 test images: 73.58 %\n",
      "[27,   352] loss: 0.830\n",
      "Accuracy of the network on the 45000 train images: 76.28 %\n",
      "Accuracy of the network on the 5000 valid images: 73.88 %\n",
      "Accuracy of the network on the 10000 test images: 73.09 %\n",
      "[28,   352] loss: 0.809\n",
      "Accuracy of the network on the 45000 train images: 76.63 %\n",
      "Accuracy of the network on the 5000 valid images: 75.60 %\n",
      "Accuracy of the network on the 10000 test images: 73.59 %\n",
      "[29,   352] loss: 0.806\n",
      "Accuracy of the network on the 45000 train images: 77.05 %\n",
      "Accuracy of the network on the 5000 valid images: 75.10 %\n",
      "Accuracy of the network on the 10000 test images: 75.51 %\n",
      "[30,   352] loss: 0.793\n",
      "Accuracy of the network on the 45000 train images: 76.04 %\n",
      "Accuracy of the network on the 5000 valid images: 72.98 %\n",
      "Accuracy of the network on the 10000 test images: 75.03 %\n",
      "[31,   352] loss: 0.782\n",
      "Accuracy of the network on the 45000 train images: 77.60 %\n",
      "Accuracy of the network on the 5000 valid images: 75.44 %\n",
      "Accuracy of the network on the 10000 test images: 75.20 %\n",
      "[32,   352] loss: 0.775\n",
      "Accuracy of the network on the 45000 train images: 78.18 %\n",
      "Accuracy of the network on the 5000 valid images: 76.06 %\n",
      "Accuracy of the network on the 10000 test images: 74.16 %\n",
      "[33,   352] loss: 0.764\n",
      "Accuracy of the network on the 45000 train images: 76.49 %\n",
      "Accuracy of the network on the 5000 valid images: 74.94 %\n",
      "Accuracy of the network on the 10000 test images: 75.29 %\n",
      "[34,   352] loss: 0.760\n",
      "Accuracy of the network on the 45000 train images: 78.38 %\n",
      "Accuracy of the network on the 5000 valid images: 76.60 %\n",
      "Accuracy of the network on the 10000 test images: 75.29 %\n",
      "[35,   352] loss: 0.760\n",
      "Accuracy of the network on the 45000 train images: 78.32 %\n",
      "Accuracy of the network on the 5000 valid images: 75.76 %\n",
      "Accuracy of the network on the 10000 test images: 76.92 %\n",
      "[36,   352] loss: 0.752\n",
      "Accuracy of the network on the 45000 train images: 79.39 %\n",
      "Accuracy of the network on the 5000 valid images: 76.58 %\n",
      "Accuracy of the network on the 10000 test images: 77.87 %\n",
      "[37,   352] loss: 0.737\n",
      "Accuracy of the network on the 45000 train images: 78.39 %\n",
      "Accuracy of the network on the 5000 valid images: 75.00 %\n",
      "Accuracy of the network on the 10000 test images: 76.56 %\n",
      "[38,   352] loss: 0.732\n",
      "Accuracy of the network on the 45000 train images: 79.60 %\n",
      "Accuracy of the network on the 5000 valid images: 76.76 %\n",
      "Accuracy of the network on the 10000 test images: 77.70 %\n",
      "[39,   352] loss: 0.718\n",
      "Accuracy of the network on the 45000 train images: 80.43 %\n",
      "Accuracy of the network on the 5000 valid images: 78.08 %\n",
      "Accuracy of the network on the 10000 test images: 77.85 %\n",
      "[40,   352] loss: 0.714\n",
      "Accuracy of the network on the 45000 train images: 78.86 %\n",
      "Accuracy of the network on the 5000 valid images: 76.42 %\n",
      "Accuracy of the network on the 10000 test images: 76.18 %\n",
      "[41,   352] loss: 0.720\n",
      "Accuracy of the network on the 45000 train images: 79.81 %\n",
      "Accuracy of the network on the 5000 valid images: 76.66 %\n",
      "Accuracy of the network on the 10000 test images: 77.25 %\n",
      "[42,   352] loss: 0.707\n",
      "Accuracy of the network on the 45000 train images: 78.71 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 5000 valid images: 76.38 %\n",
      "Accuracy of the network on the 10000 test images: 75.89 %\n",
      "[43,   352] loss: 0.696\n",
      "Accuracy of the network on the 45000 train images: 80.03 %\n",
      "Accuracy of the network on the 5000 valid images: 77.80 %\n",
      "Accuracy of the network on the 10000 test images: 76.67 %\n",
      "[44,   352] loss: 0.702\n",
      "Accuracy of the network on the 45000 train images: 77.06 %\n",
      "Accuracy of the network on the 5000 valid images: 75.20 %\n",
      "Accuracy of the network on the 10000 test images: 73.57 %\n",
      "[45,   352] loss: 0.698\n",
      "Accuracy of the network on the 45000 train images: 80.89 %\n",
      "Accuracy of the network on the 5000 valid images: 78.26 %\n",
      "Accuracy of the network on the 10000 test images: 77.98 %\n",
      "[46,   352] loss: 0.685\n",
      "Accuracy of the network on the 45000 train images: 80.13 %\n",
      "Accuracy of the network on the 5000 valid images: 77.66 %\n",
      "Accuracy of the network on the 10000 test images: 78.03 %\n",
      "[47,   352] loss: 0.696\n",
      "Accuracy of the network on the 45000 train images: 80.54 %\n",
      "Accuracy of the network on the 5000 valid images: 77.62 %\n",
      "Accuracy of the network on the 10000 test images: 78.90 %\n",
      "[48,   352] loss: 0.680\n",
      "Accuracy of the network on the 45000 train images: 80.18 %\n",
      "Accuracy of the network on the 5000 valid images: 78.22 %\n",
      "Accuracy of the network on the 10000 test images: 77.98 %\n",
      "[49,   352] loss: 0.682\n",
      "Accuracy of the network on the 45000 train images: 79.89 %\n",
      "Accuracy of the network on the 5000 valid images: 78.24 %\n",
      "Accuracy of the network on the 10000 test images: 77.05 %\n",
      "[50,   352] loss: 0.675\n",
      "Accuracy of the network on the 45000 train images: 80.20 %\n",
      "Accuracy of the network on the 5000 valid images: 77.64 %\n",
      "Accuracy of the network on the 10000 test images: 76.93 %\n",
      "[51,   352] loss: 0.678\n",
      "Accuracy of the network on the 45000 train images: 79.95 %\n",
      "Accuracy of the network on the 5000 valid images: 77.96 %\n",
      "Accuracy of the network on the 10000 test images: 78.18 %\n",
      "[52,   352] loss: 0.663\n",
      "Accuracy of the network on the 45000 train images: 80.06 %\n",
      "Accuracy of the network on the 5000 valid images: 77.46 %\n",
      "Accuracy of the network on the 10000 test images: 76.75 %\n",
      "[53,   352] loss: 0.667\n",
      "Accuracy of the network on the 45000 train images: 80.04 %\n",
      "Accuracy of the network on the 5000 valid images: 77.70 %\n",
      "Accuracy of the network on the 10000 test images: 77.43 %\n",
      "[54,   352] loss: 0.665\n",
      "Accuracy of the network on the 45000 train images: 78.28 %\n",
      "Accuracy of the network on the 5000 valid images: 75.38 %\n",
      "Accuracy of the network on the 10000 test images: 75.19 %\n",
      "[55,   352] loss: 0.664\n",
      "Accuracy of the network on the 45000 train images: 80.94 %\n",
      "Accuracy of the network on the 5000 valid images: 77.96 %\n",
      "Accuracy of the network on the 10000 test images: 76.61 %\n",
      "[56,   352] loss: 0.663\n",
      "Accuracy of the network on the 45000 train images: 82.49 %\n",
      "Accuracy of the network on the 5000 valid images: 79.64 %\n",
      "Accuracy of the network on the 10000 test images: 79.28 %\n",
      "[57,   352] loss: 0.657\n",
      "Accuracy of the network on the 45000 train images: 80.82 %\n",
      "Accuracy of the network on the 5000 valid images: 77.48 %\n",
      "Accuracy of the network on the 10000 test images: 77.40 %\n",
      "[58,   352] loss: 0.653\n",
      "Accuracy of the network on the 45000 train images: 80.69 %\n",
      "Accuracy of the network on the 5000 valid images: 77.58 %\n",
      "Accuracy of the network on the 10000 test images: 77.48 %\n",
      "[59,   352] loss: 0.649\n",
      "Accuracy of the network on the 45000 train images: 80.72 %\n",
      "Accuracy of the network on the 5000 valid images: 77.66 %\n",
      "Accuracy of the network on the 10000 test images: 77.85 %\n",
      "[60,   352] loss: 0.653\n",
      "Accuracy of the network on the 45000 train images: 80.88 %\n",
      "Accuracy of the network on the 5000 valid images: 78.46 %\n",
      "Accuracy of the network on the 10000 test images: 78.89 %\n",
      "[61,   352] loss: 0.642\n",
      "Accuracy of the network on the 45000 train images: 82.19 %\n",
      "Accuracy of the network on the 5000 valid images: 79.66 %\n",
      "Accuracy of the network on the 10000 test images: 79.27 %\n",
      "[62,   352] loss: 0.643\n",
      "Accuracy of the network on the 45000 train images: 81.06 %\n",
      "Accuracy of the network on the 5000 valid images: 78.44 %\n",
      "Accuracy of the network on the 10000 test images: 78.71 %\n",
      "[63,   352] loss: 0.639\n",
      "Accuracy of the network on the 45000 train images: 81.09 %\n",
      "Accuracy of the network on the 5000 valid images: 78.60 %\n",
      "Accuracy of the network on the 10000 test images: 77.84 %\n",
      "[64,   352] loss: 0.641\n",
      "Accuracy of the network on the 45000 train images: 81.33 %\n",
      "Accuracy of the network on the 5000 valid images: 77.64 %\n",
      "Accuracy of the network on the 10000 test images: 78.53 %\n",
      "[65,   352] loss: 0.627\n",
      "Accuracy of the network on the 45000 train images: 83.00 %\n",
      "Accuracy of the network on the 5000 valid images: 80.06 %\n",
      "Accuracy of the network on the 10000 test images: 80.17 %\n",
      "[66,   352] loss: 0.629\n",
      "Accuracy of the network on the 45000 train images: 83.14 %\n",
      "Accuracy of the network on the 5000 valid images: 79.66 %\n",
      "Accuracy of the network on the 10000 test images: 79.32 %\n",
      "[67,   352] loss: 0.618\n",
      "Accuracy of the network on the 45000 train images: 81.66 %\n",
      "Accuracy of the network on the 5000 valid images: 77.86 %\n",
      "Accuracy of the network on the 10000 test images: 79.28 %\n",
      "[68,   352] loss: 0.633\n",
      "Accuracy of the network on the 45000 train images: 81.39 %\n",
      "Accuracy of the network on the 5000 valid images: 79.10 %\n",
      "Accuracy of the network on the 10000 test images: 78.61 %\n",
      "[69,   352] loss: 0.628\n",
      "Accuracy of the network on the 45000 train images: 82.05 %\n",
      "Accuracy of the network on the 5000 valid images: 79.38 %\n",
      "Accuracy of the network on the 10000 test images: 79.97 %\n",
      "[70,   352] loss: 0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-278:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"build/bdist.linux-x86_64/egg/torchvision/datasets/cifar.py\", line 122, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"build/bdist.linux-x86_64/egg/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"build/bdist.linux-x86_64/egg/torchvision/transforms.py\", line 70, in __call__\n",
      "    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1e08f7e485f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             (epoch + 1, i + 1, running_loss / 300))\n\u001b[1;32m     29\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     print('Accuracy of the network on the 45000 train images: %5.2f %%' % (\n\u001b[1;32m     32\u001b[0m         train[epoch] * 100))\n",
      "\u001b[0;32m<ipython-input-15-e78cf1348f4f>\u001b[0m in \u001b[0;36macc\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = torch.zeros(100)\n",
    "valid = torch.zeros(100)\n",
    "test = torch.zeros(100)\n",
    "\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        #if i % 300 == 299:    # print every 2000 mini-batches\n",
    "    print('[%d, %5d] loss: %.3f' %\n",
    "            (epoch + 1, i + 1, running_loss / 300))\n",
    "    running_loss = 0.0\n",
    "    train[epoch] = acc(trainloader)\n",
    "    print('Accuracy of the network on the 45000 train images: %5.2f %%' % (\n",
    "        train[epoch] * 100))\n",
    "    \n",
    "    valid[epoch] = acc(validloader)\n",
    "    print('Accuracy of the network on the 5000 valid images: %5.2f %%' % (\n",
    "        valid[epoch] * 100))\n",
    "    \n",
    "    test[epoch] = acc(testloader2)\n",
    "    print('Accuracy of the network on the 10000 test images: %5.2f %%' % (\n",
    "        test[epoch] * 100))\n",
    "#print的时候 上面的valid和test没有标注清楚！！\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader2:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.2f %%' % (\n",
    "    100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [i for i in range(epoch)]\n",
    "plt.figure(figsize = (8,6))\n",
    "trainRate, = plt.plot(x, train.numpy()[:epoch])\n",
    "validRate, = plt.plot(x, valid.numpy()[:epoch])\n",
    "testRate, = plt.plot(x, test.numpy()[:epoch])\n",
    "plt.legend([trainRate, validRate, testRate], ['trainRate', 'validRate', 'testRate'])\n",
    "plt.xlabel('# of iteration')\n",
    "plt.ylabel('Percent Correct Classification')\n",
    "plt.title('Percent Correct Classification of CNN-1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
